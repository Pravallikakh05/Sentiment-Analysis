{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imdb Sentiment Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO7CCdcHxViz0JeC7o4D8bz"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmTU_A8tFf6u"
      },
      "source": [
        "Analyzing IMDB Data in Keras- Accuracy:  0.8588"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Joo1bEtwCygh"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJIJ91GlEnKR"
      },
      "source": [
        "\n",
        "1. Loading the data\n",
        "This dataset comes preloaded with Keras, so one simple command will get us training and testing data. There is a parameter for how many words we want to look at. We've set it at 1000, but feel free to experiment.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga1mrtV7Eood"
      },
      "source": [
        "\n",
        "# Loading the data (it's preloaded in Keras)\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=1000)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieU6EUF2EsfD"
      },
      "source": [
        "2. Examining the data\n",
        "Notice that the data has been already pre-processed, where all the words have numbers, and the reviews come in as a vector with the words that the review contains. For example, if the word 'the' is the first one in our dictionary, and a review contains the word 'the', then there is a 1 in the corresponding vector.\n",
        "\n",
        "The output comes as a vector of 1's and 0's, where 1 is a positive sentiment for the review, and 0 is negative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rOliPGOEw_0"
      },
      "source": [
        "print(x_train[0])\n",
        "print(y_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ejgjaISE5Xt"
      },
      "source": [
        "3. One-hot encoding the output\n",
        "Here, we'll turn the input vectors into (0,1)-vectors. For example, if the pre-processed vector contains the number 14, then in the processed vector, the 14th entry will be 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7v8ukZhE6H5"
      },
      "source": [
        "# One-hot encoding the output into vector mode, each of length 1000\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
        "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
        "print(x_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtiY6RGQFBWI"
      },
      "source": [
        "# One-hot encoding the output\n",
        "num_classes = 2\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUJ_pK2hFD93"
      },
      "source": [
        "4. Building the model architecture\n",
        "Build a model here using sequential. Feel free to experiment with different layers and sizes! Also, experiment adding dropout to reduce overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS31DPDoFHRh"
      },
      "source": [
        "# TODO: Build the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(2, activation='elu',input_dim=1000))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(2, activation='sigmoid',input_dim=1000))\n",
        "\n",
        "# TODO: Compile the model using a loss function and an optimizer.\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5hdcHG2FKUD"
      },
      "source": [
        "5. Training the model\n",
        "Run the model here. Experiment with different batch_size, and number of epochs!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOQQRr3SFNki"
      },
      "source": [
        "#Run the model. Feel free to experiment with different batch sizes and number of epochs.\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32,validation_data=(x_test, y_test), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpiXz8QlFSdk"
      },
      "source": [
        "6. Evaluating the model\n",
        "This will give you the accuracy of the model, as evaluated on the testing set. Can you get something over 85%?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU202a8rFTMx"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Accuracy: \", score[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}